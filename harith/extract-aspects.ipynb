{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.12.0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1/31/20</td>\n",
       "      <td>Customers Service, Quality</td>\n",
       "      <td>Not intuitive. Bad customer satisfaction servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/31/20</td>\n",
       "      <td>Customers Service, Price</td>\n",
       "      <td>I just want to upload an image as an attachmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1/31/20</td>\n",
       "      <td>General</td>\n",
       "      <td>Wow this is a fantastic program I am a new sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.12.0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>1/31/20</td>\n",
       "      <td>Dashboard</td>\n",
       "      <td>Good apart from the top of the dashboard on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.12.0.12</td>\n",
       "      <td>5</td>\n",
       "      <td>1/31/20</td>\n",
       "      <td>General</td>\n",
       "      <td>Very good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Version  Rating     Date                     Aspects  \\\n",
       "0  19.12.0.12       1  1/31/20  Customers Service, Quality   \n",
       "1      20.0.1       1  1/31/20    Customers Service, Price   \n",
       "2      20.0.1       5  1/31/20                     General   \n",
       "3  19.12.0.12       4  1/31/20                   Dashboard   \n",
       "4  19.12.0.12       5  1/31/20                     General   \n",
       "\n",
       "                                                Body  \n",
       "0  Not intuitive. Bad customer satisfaction servi...  \n",
       "1  I just want to upload an image as an attachmen...  \n",
       "2  Wow this is a fantastic program I am a new sma...  \n",
       "3  Good apart from the top of the dashboard on th...  \n",
       "4                                          Very good  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/combined-training.csv', usecols=[0, 1, 2, 3, 4])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eelrufaie/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "df.review = df.Body.str.lower()\n",
    "\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityMatcher(object):\n",
    "    name = \"entity_matcher\"\n",
    "\n",
    "    def __init__(self, nlp, terms, label):\n",
    "        patterns = [nlp.make_doc(text) for text in terms]\n",
    "        self.matcher = PhraseMatcher(nlp.vocab)\n",
    "        self.matcher.add(label, None, *patterns)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        matches = self.matcher(doc)\n",
    "        for match_id, start, end in matches:\n",
    "            span = Span(doc, start, end, label=match_id)\n",
    "            doc.ents = list(doc.ents) + [span]\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_terms = []\n",
    "for review in nlp.pipe(df.Body):\n",
    "    chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
    "    aspect_terms.append(', '.join(chunks))\n",
    "df['aspect_terms'] = aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>Body</th>\n",
       "      <th>aspect_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>19.12.0.11</td>\n",
       "      <td>3</td>\n",
       "      <td>1/12/20</td>\n",
       "      <td>Quality, Performance</td>\n",
       "      <td>The interface is really cute. On my laptop, on...</td>\n",
       "      <td>interface, laptop, data, years, thing, app, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>19.11.2</td>\n",
       "      <td>3</td>\n",
       "      <td>11/21/19</td>\n",
       "      <td>experience,data,invoicing,reports</td>\n",
       "      <td>I love the app and it has been great for us fo...</td>\n",
       "      <td>app, years, update, range, reports, invoice, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>19.12.1</td>\n",
       "      <td>1</td>\n",
       "      <td>12/16/19</td>\n",
       "      <td>data,quality,updates</td>\n",
       "      <td>The data on the app does not match the data on...</td>\n",
       "      <td>data, app, data, computer, time, way, app, pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>20.01.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1/25/20</td>\n",
       "      <td>general,quality,experience</td>\n",
       "      <td>app stinks</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>20.01.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1/12/20</td>\n",
       "      <td>integration,experience</td>\n",
       "      <td>The app isn’t syncing with online account data...</td>\n",
       "      <td>app, data, app, entry, go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/27/20</td>\n",
       "      <td>General</td>\n",
       "      <td>Very easy to use and providing all functionali...</td>\n",
       "      <td>functionality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>20.01.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1/30/20</td>\n",
       "      <td>help,data,customers service,experience,quality...</td>\n",
       "      <td>The majority of the time this app is wonderful...</td>\n",
       "      <td>majority, time, app, basis, transaction, middl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.12.0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>1/31/20</td>\n",
       "      <td>Dashboard</td>\n",
       "      <td>Good apart from the top of the dashboard on th...</td>\n",
       "      <td>top, dashboard, page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>19.12.0.12</td>\n",
       "      <td>5</td>\n",
       "      <td>1/26/20</td>\n",
       "      <td>General</td>\n",
       "      <td>This app helps me out alot I really like it.</td>\n",
       "      <td>app, alot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>19.11.2</td>\n",
       "      <td>4</td>\n",
       "      <td>11/19/19</td>\n",
       "      <td>general,experience,quality</td>\n",
       "      <td>Overall this is a fantastic app that allows me...</td>\n",
       "      <td>app, books, thing, feature, images, tool, imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>19.12.0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>1/15/20</td>\n",
       "      <td>Receipt Capture</td>\n",
       "      <td>Worst app ever!!! When logged in only options ...</td>\n",
       "      <td>app, options, help, receipts, review, receipt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>20.01.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1/27/20</td>\n",
       "      <td>general,quality,experience</td>\n",
       "      <td>See above. \\n\\nIn the office, on the site. Whe...</td>\n",
       "      <td>office, site, range, applications, years, busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>19.12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12/2/19</td>\n",
       "      <td>compatibility,quality</td>\n",
       "      <td>Please fix</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>19.12.0.11</td>\n",
       "      <td>5</td>\n",
       "      <td>1/13/20</td>\n",
       "      <td>Experience</td>\n",
       "      <td>Amazing This app can be difficult to get used ...</td>\n",
       "      <td>app, docx, templates, template, app, features,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>19.12.0.12</td>\n",
       "      <td>2</td>\n",
       "      <td>1/21/20</td>\n",
       "      <td>Quality, Mileage Tracking, Expenses</td>\n",
       "      <td>Lot of features in Mobile does not work. Like ...</td>\n",
       "      <td>Lot, features, mileage, error, expense, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1/29/20</td>\n",
       "      <td>Quality</td>\n",
       "      <td>Love QB, but this app is really glitchy. Asks ...</td>\n",
       "      <td>app, password, fingerprint, account, password,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>19.12.1</td>\n",
       "      <td>3</td>\n",
       "      <td>12/13/19</td>\n",
       "      <td>quality,payroll</td>\n",
       "      <td>I would love to be able to do up my company’s ...</td>\n",
       "      <td>company, payroll, fly, site, trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>19.12.0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1/23/20</td>\n",
       "      <td>Data</td>\n",
       "      <td>I have had this app for my business for about ...</td>\n",
       "      <td>app, business, year, money, transection, trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>19.12.1</td>\n",
       "      <td>1</td>\n",
       "      <td>12/12/19</td>\n",
       "      <td>quality,price</td>\n",
       "      <td>The various plans either offer too many bells ...</td>\n",
       "      <td>plans, bells, whistles, functions, company, To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>20.01.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1/9/20</td>\n",
       "      <td>experience,sales tax</td>\n",
       "      <td>Such an easy app to use as a new business owne...</td>\n",
       "      <td>app, owner, entrepreneur, track, purposes, sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>19.12.1</td>\n",
       "      <td>1</td>\n",
       "      <td>12/11/19</td>\n",
       "      <td>quality,currency,help,price,customers service</td>\n",
       "      <td>A pretty good product but let down by sneaky h...</td>\n",
       "      <td>product, limitations, plan, currency, section,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1/30/20</td>\n",
       "      <td>General</td>\n",
       "      <td>Good app at new start...</td>\n",
       "      <td>app, start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>19.12.0.12</td>\n",
       "      <td>5</td>\n",
       "      <td>1/25/20</td>\n",
       "      <td>General</td>\n",
       "      <td>Easy to operate and great functionality</td>\n",
       "      <td>functionality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1/10/20</td>\n",
       "      <td>General</td>\n",
       "      <td>Haven't dug deep into the options available, b...</td>\n",
       "      <td>options, experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>20.01.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1/9/20</td>\n",
       "      <td>quality,invoicing,customers</td>\n",
       "      <td>There are some glitches with a couple of the f...</td>\n",
       "      <td>glitches, couple, features, part, help, keepin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Version  Rating      Date  \\\n",
       "152  19.12.0.11       3   1/12/20   \n",
       "353     19.11.2       3  11/21/19   \n",
       "306     19.12.1       1  12/16/19   \n",
       "219     20.01.3       1   1/25/20   \n",
       "252     20.01.0       1   1/12/20   \n",
       "42          NaN       5   1/27/20   \n",
       "201     20.01.5       3   1/30/20   \n",
       "3    19.12.0.12       4   1/31/20   \n",
       "50   19.12.0.12       5   1/26/20   \n",
       "369     19.11.2       4  11/19/19   \n",
       "135  19.12.0.11       1   1/15/20   \n",
       "214     20.01.4       5   1/27/20   \n",
       "339     19.12.0       1   12/2/19   \n",
       "146  19.12.0.11       5   1/13/20   \n",
       "103  19.12.0.12       2   1/21/20   \n",
       "14       20.0.1       2   1/29/20   \n",
       "310     19.12.1       3  12/13/19   \n",
       "79   19.12.0.12       1   1/23/20   \n",
       "313     19.12.1       1  12/12/19   \n",
       "260     20.01.0       5    1/9/20   \n",
       "316     19.12.1       1  12/11/19   \n",
       "8        20.0.1       5   1/30/20   \n",
       "62   19.12.0.12       5   1/25/20   \n",
       "168         NaN       5   1/10/20   \n",
       "258     20.01.0       4    1/9/20   \n",
       "\n",
       "                                               Aspects  \\\n",
       "152                               Quality, Performance   \n",
       "353                  experience,data,invoicing,reports   \n",
       "306                               data,quality,updates   \n",
       "219                         general,quality,experience   \n",
       "252                             integration,experience   \n",
       "42                                             General   \n",
       "201  help,data,customers service,experience,quality...   \n",
       "3                                            Dashboard   \n",
       "50                                             General   \n",
       "369                         general,experience,quality   \n",
       "135                                    Receipt Capture   \n",
       "214                         general,quality,experience   \n",
       "339                              compatibility,quality   \n",
       "146                                         Experience   \n",
       "103                Quality, Mileage Tracking, Expenses   \n",
       "14                                             Quality   \n",
       "310                                    quality,payroll   \n",
       "79                                                Data   \n",
       "313                                      quality,price   \n",
       "260                               experience,sales tax   \n",
       "316      quality,currency,help,price,customers service   \n",
       "8                                              General   \n",
       "62                                             General   \n",
       "168                                            General   \n",
       "258                        quality,invoicing,customers   \n",
       "\n",
       "                                                  Body  \\\n",
       "152  The interface is really cute. On my laptop, on...   \n",
       "353  I love the app and it has been great for us fo...   \n",
       "306  The data on the app does not match the data on...   \n",
       "219                                         app stinks   \n",
       "252  The app isn’t syncing with online account data...   \n",
       "42   Very easy to use and providing all functionali...   \n",
       "201  The majority of the time this app is wonderful...   \n",
       "3    Good apart from the top of the dashboard on th...   \n",
       "50        This app helps me out alot I really like it.   \n",
       "369  Overall this is a fantastic app that allows me...   \n",
       "135  Worst app ever!!! When logged in only options ...   \n",
       "214  See above. \\n\\nIn the office, on the site. Whe...   \n",
       "339                                         Please fix   \n",
       "146  Amazing This app can be difficult to get used ...   \n",
       "103  Lot of features in Mobile does not work. Like ...   \n",
       "14   Love QB, but this app is really glitchy. Asks ...   \n",
       "310  I would love to be able to do up my company’s ...   \n",
       "79   I have had this app for my business for about ...   \n",
       "313  The various plans either offer too many bells ...   \n",
       "260  Such an easy app to use as a new business owne...   \n",
       "316  A pretty good product but let down by sneaky h...   \n",
       "8                             Good app at new start...   \n",
       "62             Easy to operate and great functionality   \n",
       "168  Haven't dug deep into the options available, b...   \n",
       "258  There are some glitches with a couple of the f...   \n",
       "\n",
       "                                          aspect_terms  \n",
       "152  interface, laptop, data, years, thing, app, da...  \n",
       "353  app, years, update, range, reports, invoice, s...  \n",
       "306  data, app, data, computer, time, way, app, pho...  \n",
       "219                                                     \n",
       "252                          app, data, app, entry, go  \n",
       "42                                       functionality  \n",
       "201  majority, time, app, basis, transaction, middl...  \n",
       "3                                 top, dashboard, page  \n",
       "50                                           app, alot  \n",
       "369  app, books, thing, feature, images, tool, imag...  \n",
       "135  app, options, help, receipts, review, receipt,...  \n",
       "214  office, site, range, applications, years, busi...  \n",
       "339                                                     \n",
       "146  app, docx, templates, template, app, features,...  \n",
       "103  Lot, features, mileage, error, expense, error,...  \n",
       "14   app, password, fingerprint, account, password,...  \n",
       "310                  company, payroll, fly, site, trip  \n",
       "79   app, business, year, money, transection, trans...  \n",
       "313  plans, bells, whistles, functions, company, To...  \n",
       "260   app, owner, entrepreneur, track, purposes, sales  \n",
       "316  product, limitations, plan, currency, section,...  \n",
       "8                                           app, start  \n",
       "62                                       functionality  \n",
       "168                                options, experience  \n",
       "258  glitches, couple, features, part, help, keepin...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Overall, it is a decent product they just need to make some tweaks</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy \n",
    "from spacy import displacy  \n",
    "text1 = \"\"\"Overall, it is a decent product they just need to make some tweaks\"\"\" \n",
    "nlp = spacy.load(\"en\") \n",
    "doc = nlp(text1) \n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E151] Trying to call nlp.update without required annotation types. Expected top-level keys: ('words', 'tags', 'heads', 'deps', 'entities', 'cats', 'links'). Got: ['e', 'n', 't', 'i', 't', 'i', 'e', 's'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-b2a90803d269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mprdnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-b2a90803d269>\u001b[0m in \u001b[0;36mtrain_spacy\u001b[0;34m(data, n_iter)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# Updating the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Losses'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# Allow dict of args to GoldParse, instead of GoldParse objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_docs_and_golds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m_format_docs_and_golds\u001b[0;34m(self, docs, golds)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0munexpected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE151\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m                 \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mdoc_objs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E151] Trying to call nlp.update without required annotation types. Expected top-level keys: ('words', 'tags', 'heads', 'deps', 'entities', 'cats', 'links'). Got: ['e', 'n', 't', 'i', 't', 'i', 'e', 's']."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "\n",
    "\n",
    "# TRAIN_DATA = [{\"content\":\"Doesn't work. After logged in, I can seem to review my accounts. This would be a great app if they could fix this issue.\",\"entities\":[[0,12,\"Quality\"]]},{\"content\":\"Love QB, but this app is really glitchy. Asks for password, loops me back, won't let me activate fingerprint. I'm signed in using Google, when I click on my Google account it asks for my password, when I enter password, it puts me in a loop. The only fix is uninstalling and then reinstalling the app. Which I have to do daily. It's incredibly frustrating.\",\"entities\":[[18,21,\"App\"],[251,254,\"Quality\"]]},{\"content\":\"Good apart from the top of the dashboard on the home page being greyed out.\",\"entities\":[[31,40,\"Dashboard\"]]},{\"content\":\"Great app for small business owners!\",\"entities\":[[6,9,\"App\"]]},{\"content\":\"Garbage, won't let you delete your account. It took hours to finally be able to delete email and account, save yourself the hassle and dont download it.\",\"entities\":[[0,7,\"Quality\"],[52,57,\"Performance\"]]},{\"content\":\"Error Everytime I log in, and requires password so often. Edit: the log in is working, but when I try to add an expense it doesn't save, the same button doesn't work\",\"entities\":[[0,5,\"Quality\"],[112,119,\"Expenses\"]]}]\n",
    "TRAIN_DATA = [{\"content\":\"what is the price of polo?\",\"entities\":[[21,25,\"PrdName\"]]},{\"content\":\"what is the price of ball?\",\"entities\":[[21,25,\"PrdName\"]]},{\"content\":\"what is the price of jegging?\",\"entities\":[[21,28,\"PrdName\"]]},{\"content\":\"what is the price of t-shirt?\",\"entities\":[[21,28,\"PrdName\"]]},{\"content\":\"what is the price of jeans?\",\"entities\":[[21,26,\"PrdName\"]]},{\"content\":\"what is the price of bat?\",\"entities\":[[21,24,\"PrdName\"]]},{\"content\":\"what is the price of shirt?\",\"entities\":[[21,26,\"PrdName\"]]},{\"content\":\"what is the price of bag?\",\"entities\":[[21,24,\"PrdName\"]]},{\"content\":\"what is the price of cup?\",\"entities\":[[21,24,\"PrdName\"]]},{\"content\":\"what is the price of jug?\",\"entities\":[[21,24,\"PrdName\"]]},{\"content\":\"what is the price of plate?\",\"entities\":[[21,26,\"PrdName\"]]},{\"content\":\"what is the price of glass?\",\"entities\":[[21,26,\"PrdName\"]]},{\"content\":\"what is the price of moniter?\",\"entities\":[[21,28,\"PrdName\"]]},{\"content\":\"what is the price of desktop?\",\"entities\":[[21,28,\"PrdName\"]]},{\"content\":\"what is the price of bottle?\",\"entities\":[[21,27,\"PrdName\"]]},{\"content\":\"what is the price of mouse?\",\"entities\":[[21,26,\"PrdName\"]]},{\"content\":\"what is the price of keyboad?\",\"entities\":[[21,28,\"PrdName\"]]},{\"content\":\"what is the price of chair?\",\"entities\":[[21,26,\"PrdName\"]]},{\"content\":\"what is the price of table?\",\"entities\":[[21,26,\"PrdName\"]]},{\"content\":\"what is the price of watch?\",\"entities\":[[21,26,\"PrdName\"]]},{\"content\":\"\",\"entities\":[]}]\n",
    "\n",
    "\n",
    "def train_spacy(data,n_iter):\n",
    "    TRAIN_DATA = data\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "       \n",
    "\n",
    "    # add labels\n",
    "    for entry in TRAIN_DATA:\n",
    "        for ent in entry.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "#     print(TRAIN_DATA)\n",
    "#     for _, annotations in TRAIN_DATA:\n",
    "#          for ent in annotations.get('entities'):\n",
    "#             ner.add_label(ent[2])\n",
    "\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            batches = minibatch(TRAIN_DATA,  size=compounding(4., 32., 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch) \n",
    "                # Updating the weights\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "                print('Losses', losses)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "                print('Losses', losses)\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "#     other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "#     with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "#         optimizer = nlp.begin_training()\n",
    "#         for itn in range(iterations):\n",
    "#             print(\"Statring iteration \" + str(itn))\n",
    "#             random.shuffle(TRAIN_DATA)\n",
    "#             losses = {}\n",
    "#             for annotations in TRAIN_DATA:\n",
    "#                 nlp.update(\n",
    "#                     [annotations.get('content')],  # batch of texts\n",
    "#                     [annotations.get('content')],  # batch of annotations\n",
    "#                     drop=0.2,  # dropout - make it harder to memorise data\n",
    "#                     sgd=optimizer,  # callable to update weights\n",
    "#                     losses=losses)\n",
    "# #             for text, annotations in TRAIN_DATA:\n",
    "# #                 print(annotations)\n",
    "# #                 nlp.update(\n",
    "# #                     [text],  # batch of texts\n",
    "# #                     [annotations],  # batch of annotations\n",
    "# #                     drop=0.2,  # dropout - make it harder to memorise data\n",
    "# #                     sgd=optimizer,  # callable to update weights\n",
    "# #                     losses=losses)\n",
    "#             print(losses)\n",
    "    return nlp\n",
    "\n",
    "\n",
    "prdnlp = train_spacy(TRAIN_DATA, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 12, 'Quality']\n",
      "Quality\n",
      "[18, 21, 'App']\n",
      "App\n",
      "[251, 254, 'Quality']\n",
      "Quality\n",
      "[31, 40, 'Dashboard']\n",
      "Dashboard\n",
      "[6, 9, 'App']\n",
      "App\n",
      "[0, 7, 'Quality']\n",
      "Quality\n",
      "[52, 57, 'Performance']\n",
      "Performance\n",
      "[0, 5, 'Quality']\n",
      "Quality\n",
      "[112, 119, 'Expenses']\n",
      "Expenses\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = [{\"content\":\"Doesn't work. After logged in, I can seem to review my accounts. This would be a great app if they could fix this issue.\",\"entities\":[[0,12,\"Quality\"]]},{\"content\":\"Love QB, but this app is really glitchy. Asks for password, loops me back, won't let me activate fingerprint. I'm signed in using Google, when I click on my Google account it asks for my password, when I enter password, it puts me in a loop. The only fix is uninstalling and then reinstalling the app. Which I have to do daily. It's incredibly frustrating.\",\"entities\":[[18,21,\"App\"],[251,254,\"Quality\"]]},{\"content\":\"Good apart from the top of the dashboard on the home page being greyed out.\",\"entities\":[[31,40,\"Dashboard\"]]},{\"content\":\"Great app for small business owners!\",\"entities\":[[6,9,\"App\"]]},{\"content\":\"Garbage, won't let you delete your account. It took hours to finally be able to delete email and account, save yourself the hassle and dont download it.\",\"entities\":[[0,7,\"Quality\"],[52,57,\"Performance\"]]},{\"content\":\"Error Everytime I log in, and requires password so often. Edit: the log in is working, but when I try to add an expense it doesn't save, the same button doesn't work\",\"entities\":[[0,5,\"Quality\"],[112,119,\"Expenses\"]]}]\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "# print(type(TRAIN_DATA))\n",
    "# for content, annotations in TRAIN_DATA:\n",
    "#     print(type(annotations))\n",
    "#     for ent in annotations.get('entities'):\n",
    "#         ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save our trained Model\n",
    "modelfile = input(\"Enter your Model Name: \")\n",
    "prdnlp.to_disk(modelfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test your text\n",
    "test_text = input(\"Enter your testing text: \")\n",
    "doc = prdnlp(test_text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 9.899998903274536}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 9.679013013839722}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 9.480179786682129}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 9.099778056144714}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 8.961228489875793}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 8.52057158946991}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 8.031827449798584}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 7.494219899177551}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 7.238992214202881}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 6.966995477676392}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 5.915162444114685}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 6.510182201862335}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 5.920004069805145}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 5.109471082687378}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 4.66792830824852}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 4.429594993591309}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 3.9506196677684784}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 5.472369186580181}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 4.413455858826637}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 4.84555222094059}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 3.5072908587753773}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 3.9548139423131943}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 4.350941251963377}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 3.836020093411207}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 5.014641165733337}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 3.955701599828899}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 4.740117631852627}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 3.0978750344365835}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 3.2437684759497643}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 2.388662677258253}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 2.311972491443157}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 2.8818992394953966}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 2.321086425334215}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 2.5077105537056923}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 4.829967565834522}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 3.9077605232596397}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 2.8300099475309253}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 1.9971804171800613}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 3.149895653128624}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 3.0348716005682945}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 3.0143236350268126}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 2.262505581602454}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 3.2615947611629963}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 2.5239257020584773}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 2.4415815661195666}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 2.243159808218479}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 2.2460601375059923}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 1.2035739701241255}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 1.8583133611828089}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 1.9336641707923263}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 1.4871653774753213}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 1.2545101586729288}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 2.1257787491194904}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 1.8203126382431947}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.8164988591161091}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 1.1951607942464761}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 2.414423618640285}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 3.037676514737541}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 2.5304495019372553}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.7196160581374897}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.8307411902351305}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.2561793723496635}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.38655039251898415}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.6441045864976331}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.6063417972231946}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.11601281409093644}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 1.149621760003356}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.3561777405884641}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.35733535090548685}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.08983619516220642}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.47217568370251684}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.013924008663877885}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.0360948448806937}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.01717122027488216}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.0003474920308548235}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.04092681680297083}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.028164613580173636}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.6132919709208293}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.00445659249385244}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.013903268069271668}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.5516877819379387}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 2.5592377243421893e-05}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.30348736026962797}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.00036059445716318805}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 2.165909388285314e-06}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.001308873283555556}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.09129668523027235}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.0023327796836767334}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 8.179524483087341e-05}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 1.1768345276719216e-05}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 5.4690773467168385e-05}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.017098450674226884}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.08831391423668689}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.001152720669559812}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 1.7301059547404282e-05}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.0009548315034363236}\n",
      "('Who is Shaka Khan?', 'I like London and Berlin.')\n",
      "({'entities': [(7, 17, 'PERSON')]}, {'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]})\n",
      "Losses {'ner': 0.00023768146035083038}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 1.0452170239538816e-05}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.000918885173782651}\n",
      "('I like London and Berlin.', 'Who is Shaka Khan?')\n",
      "({'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]}, {'entities': [(7, 17, 'PERSON')]})\n",
      "Losses {'ner': 0.012261610101805293}\n",
      "Entities [('London', 'LOC'), ('Berlin', 'LOC')]\n",
      "Tokens [('I', '', 2), ('like', '', 2), ('London', 'LOC', 3), ('and', '', 2), ('Berlin', 'LOC', 3), ('.', '', 2)]\n",
      "Entities [('Shaka Khan', 'PERSON')]\n",
      "Tokens [('Who', '', 2), ('is', '', 2), ('Shaka', 'PERSON', 3), ('Khan', 'PERSON', 1), ('?', '', 2)]\n"
     ]
    }
   ],
   "source": [
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "# training data\n",
    "TRAIN_DATA = [\n",
    "    (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "    (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n",
    "]\n",
    "\n",
    "# TRAIN_DATA = [\n",
    "#     {\"content\":\"Doesn't work. After logged in, I can seem to review my accounts. This would be a great app if they could fix this issue.\",\"entities\":[[0,12,\"Quality\"]]},{\"content\":\"Love QB, but this app is really glitchy. Asks for password, loops me back, won't let me activate fingerprint. I'm signed in using Google, when I click on my Google account it asks for my password, when I enter password, it puts me in a loop. The only fix is uninstalling and then reinstalling the app. Which I have to do daily. It's incredibly frustrating.\",\"entities\":[[18,21,\"App\"],[251,254,\"Quality\"]]},{\"content\":\"Good apart from the top of the dashboard on the home page being greyed out.\",\"entities\":[[31,40,\"Dashboard\"]]},{\"content\":\"Great app for small business owners!\",\"entities\":[[6,9,\"App\"]]},{\"content\":\"Garbage, won't let you delete your account. It took hours to finally be able to delete email and account, save yourself the hassle and dont download it.\",\"entities\":[[0,7,\"Quality\"],[52,57,\"Performance\"]]},{\"content\":\"Error Everytime I log in, and requires password so often. Edit: the log in is working, but when I try to add an expense it doesn't save, the same button doesn't work\",\"entities\":[[0,5,\"Quality\"],[112,119,\"Expenses\"]]}]\n",
    "\n",
    "\n",
    "\n",
    "@plac.annotations(\n",
    "    model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
    "    output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
    "    n_iter=(\"Number of training iterations\", \"option\", \"n\", int),\n",
    ")\n",
    "def main(model=None, output_dir=None, n_iter=100):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        # reset and initialize the weights randomly – but only if we're\n",
    "        # training a new model\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                print(texts)\n",
    "                print(annotations)\n",
    "                nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(\"Losses\", losses)\n",
    "\n",
    "    # test the trained model\n",
    "    for text, _ in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "        print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        for text, _ in TRAIN_DATA:\n",
    "            doc = nlp2(text)\n",
    "            print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "            print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "\n",
    "prdnlp = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
