{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('ASC', 'qb', 'restaurant or laptop or qb')\n",
    "flags.DEFINE_string('DSC', 'yelp', '{yelp, twitter} for restaurant & {amazon, twitter} for laptop')\n",
    "flags.DEFINE_integer('batch_size', 128, 'number of example per batch')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'learning rate')\n",
    "#flags.DEFINE_float('learning_rate', 0.01, 'learning rate')\n",
    "flags.DEFINE_integer('n_iter', 25, 'training iteration')\n",
    "#flags.DEFINE_integer('n_iter', 2, 'training iteration')\n",
    "# We slightly modify the training procedure. Feeding all DSC data in ONE epoch can get better results.\n",
    "flags.DEFINE_float('gamma', 0.1, '{0.1, 0.1, 0.9, 0.2} for {res+yelp, res+twitter, laptop+amazon, laptop+twitter')\n",
    "flags.DEFINE_integer('embedding_dim', 300, 'dimension of word embedding')\n",
    "flags.DEFINE_integer('position_dim', 100, 'dimension of position embedding')\n",
    "#flags.DEFINE_integer('max_sentence_len', 85, 'max number of tokens per sentence')\n",
    "flags.DEFINE_integer('max_sentence_len', 210, 'max number of tokens per sentence')\n",
    "flags.DEFINE_integer('max_target_len', 25, 'max number of tokens per target')\n",
    "flags.DEFINE_float('keep_prob1', 0.5, 'dropout keep prob1')\n",
    "flags.DEFINE_float('keep_prob2', 1.0, 'dropout keep prob2')\n",
    "# Parameters for capsule layers.\n",
    "flags.DEFINE_integer('filter_size', 3, 'filter_size')\n",
    "flags.DEFINE_integer('sc_num', 16, 'sc_num')\n",
    "flags.DEFINE_integer('sc_dim', 16, 'sc_dim')\n",
    "flags.DEFINE_integer('cc_num',  3, 'cc_num')\n",
    "flags.DEFINE_integer('cc_dim', 24, 'cc_dim')\n",
    "flags.DEFINE_integer('iter_routing', 3, 'routing iteration')\n",
    "flags.DEFINE_bool(\"reuse_embedding\", True, \"reuse word embedding & id, True or False\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    start_time = time.time()\n",
    "    info = ''\n",
    "    index = 0\n",
    "    \n",
    "    for name, value in FLAGS.__flags.items():\n",
    "        value = value.value\n",
    "        if index < 19:\n",
    "            info += '{}:{}  '.format(name, value)\n",
    "        if index in [5, 11]:\n",
    "            info += '\\n'\n",
    "        index += 1\n",
    "    print('\\n{:-^80}'.format('Parameters'))\n",
    "    print(info + '\\n')\n",
    "    \n",
    "    print('---------')\n",
    "    print(FLAGS.ASC)\n",
    "    \n",
    "    data_path = 'data/{}/'.format(FLAGS.ASC)\n",
    "    \n",
    "    if not FLAGS.reuse_embedding :\n",
    "        print('Initialize Word Dictionary & Embedding')\n",
    "        word_dict = data_init(data_path, FLAGS.DSC)\n",
    "        w2v = init_word_embeddings(data_path, word_dict, FLAGS.DSC)\n",
    "    else:\n",
    "        print('Reuse Word Dictionary & Embedding')\n",
    "        with open(data_path + FLAGS.DSC + '_word2id.txt', 'r', encoding='utf-8') as f:\n",
    "            word_dict = eval(f.read())\n",
    "        w2v = np.load(data_path + FLAGS.DSC + '_word_embedding.npy')\n",
    "    \n",
    "    #print(w2v)\n",
    "    #print(word_dict)\n",
    "    \n",
    "    for i in range(15):\n",
    "        model = MODEL(FLAGS, w2v, word_dict, data_path)\n",
    "        model.run()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('Running Time: {:.0f}m {:.0f}s'.format((end_time-start_time) // 60, (end_time-start_time) % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------Parameters-----------------------------------\n",
      "logtostderr:False  alsologtostderr:False  log_dir:  v:0  verbosity:0  stderrthreshold:fatal  \n",
      "showprefixforinfo:True  run_with_pdb:False  pdb_post_mortem:False  run_with_profiling:False  profile_file:None  use_cprofile_for_profiling:True  \n",
      "only_check_args:False  op_conversion_fallback_to_while_loop:False  test_random_seed:301  test_srcdir:  test_tmpdir:/tmp/absl_testing  test_randomize_ordering_seed:  xml_output_file:  \n",
      "\n",
      "---------\n",
      "qb\n",
      "Reuse Word Dictionary & Embedding\n",
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:47: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:02.471475 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:47: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:54: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:02.485881 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:54: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:66: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:02.519736 140637630826304 deprecation.py:506] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:66: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:72: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:02.537891 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:72: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/capsule.py:17: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:02.543081 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/capsule.py:17: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:02.568351 140637630826304 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "I0406 05:15:02.844444 140637630826304 utils.py:141] NumExpr defaulting to 1 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:03.210648 140637630826304 deprecation.py:323] From /home/rmajumder/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/capsule.py:48: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:03.283674 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/capsule.py:48: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:126: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:03.592290 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:126: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:128: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:03.603132 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:128: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:03.844368 140637630826304 deprecation.py:323] From /home/rmajumder/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:134: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:05.345842 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:134: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:135: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0406 05:15:05.361283 140637630826304 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb-2/model.py:135: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "/home/rmajumder/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter0--------------------------------------\n",
      "train loss=35.269719, dev loss=19.242122, dev acc=0.6328, step=105\n",
      "test acc=0.6310, test precision=0.4897, test recall=0.4878, test f1=0.4397\n",
      "smalltest acc=0.4286, test precision=0.2143, test recall=0.5000, test f1=0.3000\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter1--------------------------------------\n",
      "train loss=33.573501, dev loss=18.619680, dev acc=0.5278, step=210\n",
      "test acc=0.5329, test precision=0.6283, test recall=0.4950, test f1=0.3817\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 1]\n",
      "======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmajumder/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------Iter2--------------------------------------\n",
      "train loss=29.964068, dev loss=15.016885, dev acc=0.6281, step=315\n",
      "test acc=0.6331, test precision=0.6626, test recall=0.5989, test f1=0.5345\n",
      "smalltest acc=0.4286, test precision=0.1667, test recall=0.2500, test f1=0.2000\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter3--------------------------------------\n",
      "train loss=26.724970, dev loss=14.577481, dev acc=0.5717, step=420\n",
      "test acc=0.5754, test precision=0.6737, test recall=0.5705, test f1=0.4560\n",
      "smalltest acc=0.4286, test precision=0.1667, test recall=0.2500, test f1=0.2000\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter4--------------------------------------\n",
      "train loss=26.068883, dev loss=14.417945, dev acc=0.5724, step=525\n",
      "test acc=0.5754, test precision=0.6657, test recall=0.5723, test f1=0.4569\n",
      "smalltest acc=0.4286, test precision=0.2000, test recall=0.2500, test f1=0.2222\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter5--------------------------------------\n",
      "train loss=25.623221, dev loss=14.279432, dev acc=0.5849, step=630\n",
      "test acc=0.5936, test precision=0.6651, test recall=0.5839, test f1=0.4777\n",
      "smalltest acc=0.4286, test precision=0.2000, test recall=0.2500, test f1=0.2222\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter6--------------------------------------\n",
      "train loss=25.405244, dev loss=14.249833, dev acc=0.5893, step=735\n",
      "test acc=0.6027, test precision=0.6718, test recall=0.5937, test f1=0.4883\n",
      "smalltest acc=0.4286, test precision=0.2000, test recall=0.2500, test f1=0.2222\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter7--------------------------------------\n",
      "train loss=25.112192, dev loss=14.266191, dev acc=0.5889, step=840\n",
      "test acc=0.6024, test precision=0.6750, test recall=0.6000, test f1=0.4869\n",
      "smalltest acc=0.4286, test precision=0.2000, test recall=0.2500, test f1=0.2222\n",
      "max step:1, early stop step:1\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter8--------------------------------------\n",
      "train loss=24.900590, dev loss=14.228059, dev acc=0.6034, step=945\n",
      "test acc=0.6189, test precision=0.6748, test recall=0.6080, test f1=0.5062\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter9--------------------------------------\n",
      "train loss=24.675475, dev loss=14.147788, dev acc=0.6180, step=1050\n",
      "test acc=0.6344, test precision=0.6793, test recall=0.6240, test f1=0.5284\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter10-------------------------------------\n",
      "train loss=24.492550, dev loss=14.222698, dev acc=0.6271, step=1155\n",
      "test acc=0.6428, test precision=0.6807, test recall=0.6286, test f1=0.5358\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:1, early stop step:1\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter11-------------------------------------\n",
      "train loss=24.329773, dev loss=14.225359, dev acc=0.6166, step=1260\n",
      "test acc=0.6341, test precision=0.6848, test recall=0.6354, test f1=0.5314\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:2, early stop step:2\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter12-------------------------------------\n",
      "train loss=24.140686, dev loss=14.150880, dev acc=0.6180, step=1365\n",
      "test acc=0.6344, test precision=0.6848, test recall=0.6336, test f1=0.5300\n",
      "smalltest acc=0.4286, test precision=0.2000, test recall=0.2500, test f1=0.2222\n",
      "max step:3, early stop step:3\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter13-------------------------------------\n",
      "train loss=23.993301, dev loss=14.245413, dev acc=0.6196, step=1470\n",
      "test acc=0.6374, test precision=0.6816, test recall=0.6330, test f1=0.5315\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:4, early stop step:4\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter14-------------------------------------\n",
      "train loss=23.912278, dev loss=14.108572, dev acc=0.6456, step=1575\n",
      "test acc=0.6658, test precision=0.6903, test recall=0.6549, test f1=0.5657\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:4, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter15-------------------------------------\n",
      "train loss=23.785450, dev loss=14.214420, dev acc=0.6254, step=1680\n",
      "test acc=0.6476, test precision=0.6911, test recall=0.6515, test f1=0.5475\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:4, early stop step:1\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter16-------------------------------------\n",
      "train loss=23.699182, dev loss=14.132816, dev acc=0.6423, step=1785\n",
      "test acc=0.6610, test precision=0.6944, test recall=0.6615, test f1=0.5625\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:4, early stop step:2\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter17-------------------------------------\n",
      "train loss=23.594244, dev loss=14.182945, dev acc=0.6520, step=1890\n",
      "test acc=0.6752, test precision=0.6929, test recall=0.6641, test f1=0.5758\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:4, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter18-------------------------------------\n",
      "train loss=23.424726, dev loss=14.161720, dev acc=0.6666, step=1995\n",
      "test acc=0.6884, test precision=0.6975, test recall=0.6758, test f1=0.5907\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:4, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 1, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter19-------------------------------------\n",
      "train loss=23.427163, dev loss=14.162412, dev acc=0.6625, step=2100\n",
      "test acc=0.6853, test precision=0.6993, test recall=0.6793, test f1=0.5907\n",
      "smalltest acc=0.5714, test precision=0.2222, test recall=0.3333, test f1=0.2667\n",
      "max step:4, early stop step:1\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter20-------------------------------------\n",
      "train loss=23.297892, dev loss=14.164433, dev acc=0.6780, step=2205\n",
      "test acc=0.7096, test precision=0.7001, test recall=0.6881, test f1=0.6124\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:4, early stop step:0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
