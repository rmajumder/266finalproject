{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('ASC', 'qb', 'restaurant or laptop or qb')\n",
    "flags.DEFINE_string('DSC', 'yelp', '{yelp, twitter} for restaurant & {amazon, twitter} for laptop')\n",
    "flags.DEFINE_integer('batch_size', 128, 'number of example per batch')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'learning rate')\n",
    "flags.DEFINE_integer('n_iter', 25, 'training iteration')\n",
    "#flags.DEFINE_integer('n_iter', 2, 'training iteration')\n",
    "# We slightly modify the training procedure. Feeding all DSC data in ONE epoch can get better results.\n",
    "flags.DEFINE_float('gamma', 0.1, '{0.1, 0.1, 0.9, 0.2} for {res+yelp, res+twitter, laptop+amazon, laptop+twitter')\n",
    "flags.DEFINE_integer('embedding_dim', 300, 'dimension of word embedding')\n",
    "flags.DEFINE_integer('position_dim', 100, 'dimension of position embedding')\n",
    "#flags.DEFINE_integer('max_sentence_len', 85, 'max number of tokens per sentence')\n",
    "flags.DEFINE_integer('max_sentence_len', 95, 'max number of tokens per sentence')\n",
    "flags.DEFINE_integer('max_target_len', 25, 'max number of tokens per target')\n",
    "flags.DEFINE_float('keep_prob1', 0.5, 'dropout keep prob1')\n",
    "flags.DEFINE_float('keep_prob2', 1.0, 'dropout keep prob2')\n",
    "# Parameters for capsule layers.\n",
    "flags.DEFINE_integer('filter_size', 3, 'filter_size')\n",
    "flags.DEFINE_integer('sc_num', 16, 'sc_num')\n",
    "flags.DEFINE_integer('sc_dim', 16, 'sc_dim')\n",
    "flags.DEFINE_integer('cc_num',  3, 'cc_num')\n",
    "flags.DEFINE_integer('cc_dim', 24, 'cc_dim')\n",
    "flags.DEFINE_integer('iter_routing', 3, 'routing iteration')\n",
    "flags.DEFINE_bool(\"reuse_embedding\", False, \"reuse word embedding & id, True or False\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    start_time = time.time()\n",
    "    info = ''\n",
    "    index = 0\n",
    "    \n",
    "    for name, value in FLAGS.__flags.items():\n",
    "        value = value.value\n",
    "        if index < 19:\n",
    "            info += '{}:{}  '.format(name, value)\n",
    "        if index in [5, 11]:\n",
    "            info += '\\n'\n",
    "        index += 1\n",
    "    print('\\n{:-^80}'.format('Parameters'))\n",
    "    print(info + '\\n')\n",
    "    \n",
    "    print('---------')\n",
    "    print(FLAGS.ASC)\n",
    "    \n",
    "    data_path = 'data/{}/'.format(FLAGS.ASC)\n",
    "    \n",
    "    if not FLAGS.reuse_embedding :\n",
    "        print('Initialize Word Dictionary & Embedding')\n",
    "        word_dict = data_init(data_path, FLAGS.DSC)\n",
    "        w2v = init_word_embeddings(data_path, word_dict, FLAGS.DSC)\n",
    "    else:\n",
    "        print('Reuse Word Dictionary & Embedding')\n",
    "        with open(data_path + FLAGS.DSC + '_word2id.txt', 'r', encoding='utf-8') as f:\n",
    "            word_dict = eval(f.read())\n",
    "        w2v = np.load(data_path + FLAGS.DSC + '_word_embedding.npy')\n",
    "    \n",
    "    #print(w2v)\n",
    "    #print(word_dict)\n",
    "    \n",
    "    model = MODEL(FLAGS, w2v, word_dict, data_path)\n",
    "    model.run()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('Running Time: {:.0f}m {:.0f}s'.format((end_time-start_time) // 60, (end_time-start_time) % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------Parameters-----------------------------------\n",
      "logtostderr:False  alsologtostderr:False  log_dir:  v:0  verbosity:0  stderrthreshold:fatal  \n",
      "showprefixforinfo:True  run_with_pdb:False  pdb_post_mortem:False  run_with_profiling:False  profile_file:None  use_cprofile_for_profiling:True  \n",
      "only_check_args:False  op_conversion_fallback_to_while_loop:False  test_random_seed:301  test_srcdir:  test_tmpdir:/tmp/absl_testing  test_randomize_ordering_seed:  xml_output_file:  \n",
      "\n",
      "---------\n",
      "qb\n",
      "Initialize Word Dictionary & Embedding\n",
      "Processing train/review.txt...\n",
      "Processing train/yelp_review.txt...\n",
      "Processing dev/review.txt...\n",
      "Processing test/review.txt...\n",
      "Processing smalltest/review.txt...\n",
      "max_sentence_length 116\n",
      "path data/qb/\n",
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:46: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:48.432594 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:46: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:52: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:48.457059 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:52: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am TransCap.\n",
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:65: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:48.513461 140644103006016 deprecation.py:506] From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:65: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:48.533741 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/capsule.py:17: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:48.539425 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/capsule.py:17: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:48.662359 140644103006016 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "I0322 00:41:50.935580 140644103006016 utils.py:141] NumExpr defaulting to 1 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:53.417777 140644103006016 deprecation.py:323] From /home/rmajumder/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/capsule.py:48: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:53.623821 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/capsule.py:48: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:116: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:54.059880 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:116: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:118: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:54.070706 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:118: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:54.356336 140644103006016 deprecation.py:323] From /home/rmajumder/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:124: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:55.843035 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:124: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:125: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0322 00:41:56.350179 140644103006016 module_wrapper.py:139] From /home/rmajumder/266proj/266finalproject/transcap-qb/model.py:125: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "/home/rmajumder/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter0--------------------------------------\n",
      "train loss=22.508092, dev loss=8.689588, dev acc=0.4778, step=280\n",
      "test acc=0.4943, test precision=0.1653, test recall=0.3333, test f1=0.2210\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[1, 1, 2, 2, 2, 2, 1]\n",
      "======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmajumder/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------Iter1--------------------------------------\n",
      "train loss=21.595555, dev loss=7.324738, dev acc=0.6328, step=560\n",
      "test acc=0.6322, test precision=0.6239, test recall=0.5721, test f1=0.5123\n",
      "smalltest acc=0.2857, test precision=0.1667, test recall=0.1667, test f1=0.1667\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter2--------------------------------------\n",
      "train loss=18.688177, dev loss=6.696016, dev acc=0.5831, step=840\n",
      "test acc=0.5831, test precision=0.6327, test recall=0.5682, test f1=0.4693\n",
      "smalltest acc=0.4286, test precision=0.1667, test recall=0.2500, test f1=0.2000\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter3--------------------------------------\n",
      "train loss=17.551607, dev loss=6.740597, dev acc=0.7028, step=1120\n",
      "test acc=0.7096, test precision=0.6353, test recall=0.6224, test f1=0.5691\n",
      "smalltest acc=0.4286, test precision=0.1667, test recall=0.2500, test f1=0.2000\n",
      "max step:0, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 1]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter4--------------------------------------\n",
      "train loss=17.166138, dev loss=6.736212, dev acc=0.6983, step=1400\n",
      "test acc=0.7011, test precision=0.6396, test recall=0.6302, test f1=0.5667\n",
      "smalltest acc=0.4286, test precision=0.1667, test recall=0.2500, test f1=0.2000\n",
      "max step:1, early stop step:1\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter5--------------------------------------\n",
      "train loss=16.921801, dev loss=6.847523, dev acc=0.7344, step=1680\n",
      "test acc=0.7395, test precision=0.6448, test recall=0.6483, test f1=0.5924\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter6--------------------------------------\n",
      "train loss=16.666201, dev loss=6.660765, dev acc=0.7592, step=1960\n",
      "test acc=0.7755, test precision=0.6616, test recall=0.6891, test f1=0.6292\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter7--------------------------------------\n",
      "train loss=16.413569, dev loss=6.470743, dev acc=0.8111, step=2240\n",
      "test acc=0.8276, test precision=0.6703, test recall=0.7034, test f1=0.6644\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter8--------------------------------------\n",
      "train loss=16.034369, dev loss=6.286917, dev acc=0.8292, step=2520\n",
      "test acc=0.8444, test precision=0.6811, test recall=0.7205, test f1=0.6830\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter9--------------------------------------\n",
      "train loss=15.720740, dev loss=6.194059, dev acc=0.8442, step=2800\n",
      "test acc=0.8659, test precision=0.7023, test recall=0.7453, test f1=0.7117\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter10-------------------------------------\n",
      "train loss=15.424301, dev loss=6.239718, dev acc=0.8510, step=3080\n",
      "test acc=0.8705, test precision=0.7086, test recall=0.7486, test f1=0.7194\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter11-------------------------------------\n",
      "train loss=15.249020, dev loss=6.178360, dev acc=0.8600, step=3360\n",
      "test acc=0.8820, test precision=0.7268, test recall=0.7616, test f1=0.7385\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter12-------------------------------------\n",
      "train loss=14.993875, dev loss=6.198774, dev acc=0.8608, step=3640\n",
      "test acc=0.8927, test precision=0.7435, test recall=0.7694, test f1=0.7535\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter13-------------------------------------\n",
      "train loss=14.926020, dev loss=6.106381, dev acc=0.8698, step=3920\n",
      "test acc=0.8981, test precision=0.7577, test recall=0.7733, test f1=0.7644\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n",
      "======\n",
      "[2, 0, 0, 2, 2, 0, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "======\n",
      "\n",
      "-------------------------------------Iter14-------------------------------------\n",
      "train loss=14.777931, dev loss=6.119282, dev acc=0.8706, step=4200\n",
      "test acc=0.9004, test precision=0.7621, test recall=0.7750, test f1=0.7678\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:1, early stop step:0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
