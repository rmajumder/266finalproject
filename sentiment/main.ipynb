{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference - https://github.com/NLPWM-WHU/TransCap/tree/master/TransCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *\n",
    "from generate_tf_flags import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = assign_flag_values(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    start_time = time.time()\n",
    "    info = ''\n",
    "    index = 0\n",
    "    \n",
    "    for name, value in FLAGS.__flags.items():\n",
    "        value = value.value\n",
    "        if index < 19:\n",
    "            info += '{}:{}  '.format(name, value)\n",
    "        if index in [5, 11]:\n",
    "            info += '\\n'\n",
    "        index += 1\n",
    "    print('\\n{:-^80}'.format('Parameters'))\n",
    "    print(info + '\\n')\n",
    "    \n",
    "    print('---------')\n",
    "    print(FLAGS.ASC)\n",
    "    \n",
    "    data_path = '../data/{}/'.format(FLAGS.ASC)\n",
    "    \n",
    "    if not FLAGS.reuse_embedding :\n",
    "        print('Initialize Word Dictionary & Embedding')\n",
    "        word_dict = data_init(data_path, FLAGS.DSC)\n",
    "        w2v = init_word_embeddings(data_path, word_dict, FLAGS.DSC)\n",
    "    else:\n",
    "        print('Reuse Word Dictionary & Embedding')\n",
    "        with open(data_path + FLAGS.DSC + '_word2id.txt', 'r', encoding='utf-8') as f:\n",
    "            word_dict = eval(f.read())\n",
    "        w2v = np.load(data_path + FLAGS.DSC + '_word_embedding.npy')\n",
    "    \n",
    "    for i in range(15):\n",
    "        model = MODEL(FLAGS, w2v, word_dict, data_path)\n",
    "        model.run()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('Running Time: {:.0f}m {:.0f}s'.format((end_time-start_time) // 60, (end_time-start_time) % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------Parameters-----------------------------------\n",
      "logtostderr:False  alsologtostderr:False  log_dir:  v:0  verbosity:0  stderrthreshold:fatal  \n",
      "showprefixforinfo:True  run_with_pdb:False  pdb_post_mortem:False  run_with_profiling:False  profile_file:None  use_cprofile_for_profiling:True  \n",
      "only_check_args:False  op_conversion_fallback_to_while_loop:False  test_random_seed:301  test_srcdir:  test_tmpdir:/tmp/absl_testing  test_randomize_ordering_seed:  xml_output_file:  \n",
      "\n",
      "---------\n",
      "qb\n",
      "Reuse Word Dictionary & Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0414 05:49:00.244185 140672324503360 utils.py:141] NumExpr defaulting to 1 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------Iter0--------------------------------------\n",
      "train loss=18.778585, dev loss=19.463652, dev acc=0.5088, step=53\n",
      "test acc=0.5113, test precision=0.2267, test recall=0.3366, test f1=0.2324\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:0, early stop step:0\n",
      "\n",
      "-------------------------------------Iter1--------------------------------------\n",
      "train loss=17.136338, dev loss=19.295951, dev acc=0.5118, step=106\n",
      "test acc=0.5154, test precision=0.2169, test recall=0.3498, test f1=0.2551\n",
      "smalltest acc=0.5714, test precision=0.2857, test recall=0.5000, test f1=0.3636\n",
      "max step:0, early stop step:0\n",
      "\n",
      "-------------------------------------Iter2--------------------------------------\n",
      "train loss=17.035088, dev loss=19.159654, dev acc=0.4868, step=159\n",
      "test acc=0.4897, test precision=0.3132, test recall=0.4921, test f1=0.3485\n",
      "smalltest acc=0.4286, test precision=0.2000, test recall=0.2500, test f1=0.2222\n",
      "max step:0, early stop step:0\n",
      "\n",
      "-------------------------------------Iter3--------------------------------------\n",
      "train loss=16.842322, dev loss=18.579270, dev acc=0.3833, step=212\n",
      "test acc=0.3926, test precision=0.3060, test recall=0.4612, test f1=0.3048\n",
      "smalltest acc=0.2857, test precision=0.1667, test recall=0.1667, test f1=0.1667\n",
      "max step:0, early stop step:0\n",
      "\n",
      "-------------------------------------Iter4--------------------------------------\n",
      "train loss=15.856216, dev loss=16.440398, dev acc=0.4702, step=265\n",
      "test acc=0.4728, test precision=0.6605, test recall=0.5194, test f1=0.3930\n",
      "smalltest acc=0.2857, test precision=0.1667, test recall=0.1667, test f1=0.1667\n",
      "max step:0, early stop step:0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
